# â±ï¸ Twitter API Rate Limits & Optimization

## ğŸš¨ The Problem: Free Tier is SLOW

Twitter API Free Tier: **1 request per 15 minutes** (900 seconds)

### Old Approach (Terrible!)
```
For 10 threads:
- Get user_id: 1 call (15 min)
- Get bookmarks: 1 call (15 min)
- For each thread:
  - Get tweet: 1 call (15 min)
  - Search conversation: 1 call (15 min)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total: 2 + (10 Ã— 2) = 22 calls
Time: 22 Ã— 15 minutes = 330 minutes = 5.5 hours!
```

### New Approach (Optimized!)
```
For 10 threads:
- Get user_id: 1 call (cached forever!)
- Get bookmarks: 1 call (15 min)
- For each thread:
  - Search conversation: 1 call (15 min)
    (Skip individual tweet fetch!)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total: 1 + 1 + (10 Ã— 1) = 12 calls
Time: 12 Ã— 15 minutes = 180 minutes = 3 hours
```

**Saved: 2.5 hours!** ğŸ‰

---

## ğŸ’¡ Optimizations Applied

### 1. **Cache User ID**
```python
self.cached_user_id = None  # Cached after first fetch
```
- Fetched once per session
- Saves 1 API call = 15 minutes

### 2. **Single Search Query**
```python
# OLD: 2 calls per thread
GET /tweets/{id}              # 15 min
GET /search?conversation_id   # 15 min

# NEW: 1 call per thread
GET /search?conversation_id AND from:author_id  # 15 min
```
- Combined query using `from:author_id` filter
- Saves 1 API call per thread = 15 min Ã— N threads

### 3. **Batch Processing Architecture**
```
Phase 1: Fetch ALL threads from Twitter (15 min per thread)
Phase 2: Process with LLM (no API calls, instant!)
```
- All Twitter calls upfront
- LLM processing happens locally (no waiting)

---

## ğŸ“Š Real Example: 5 Threads

### Before Optimization
```
1. Get user_id     â†’  0:00 - 0:15  âœ“
2. Get bookmarks   â†’  0:15 - 0:30  âœ“
3. Thread 1 tweet  â†’  0:30 - 0:45  âœ“
4. Thread 1 search â†’  0:45 - 1:00  âœ“
5. Thread 2 tweet  â†’  1:00 - 1:15  âœ“
6. Thread 2 search â†’  1:15 - 1:30  âœ“
...
12. Thread 5 search â†’ 2:45 - 3:00  âœ“
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total: 3 hours
```

### After Optimization
```
1. Get user_id (cached)  â†’  instant!
2. Get bookmarks         â†’  0:00 - 0:15  âœ“
3. Thread 1 search       â†’  0:15 - 0:30  âœ“
4. Thread 2 search       â†’  0:30 - 0:45  âœ“
5. Thread 3 search       â†’  0:45 - 1:00  âœ“
6. Thread 4 search       â†’  1:00 - 1:15  âœ“
7. Thread 5 search       â†’  1:15 - 1:30  âœ“
8. LLM processing        â†’  1:30 - 1:40  (all threads, instant!)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Total: 1.5 hours (50% faster!)
```

---

## ğŸ¯ Best Practices

### 1. **Process in Batches**
```bash
# Don't do this:
threadsmith add url1  # 30 min
threadsmith add url2  # 30 min
threadsmith add url3  # 30 min
# = 90 minutes

# Do this instead:
# Bookmark all threads in browser
threadsmith sync      # 45 min for all 3
# = 45 minutes
```

### 2. **Bookmark First, Sync Later**
- Browse Twitter normally
- Bookmark interesting threads
- Run `threadsmith sync` once at end of day
- Process all at once

### 3. **Use Saved Sessions**
- User ID cached per session
- Don't restart unnecessarily
- Reuse same terminal session

### 4. **Plan Ahead**
- Free tier = ~4 threads per hour max
- Plan your syncs accordingly
- Best: End of day batch

---

## âš ï¸ What to Expect

When you run `threadsmith sync`:

```
ğŸ” Select model for processing...
ğŸ’¬ Select a model:
  gemma3n-E2B-it-Q4_0 (2.8 GB)
âœ“ qwen3-14B-Q4_K_M (8.4 GB)
  gemma3-27B-it-qat-Q4_0 (14.5 GB)

âœ“ Using: qwen3-14B-Q4_K_M.gguf (8.4 GB)

ğŸ”„ Starting bookmark sync...
âœ“ Found 10 bookmarks
ğŸ“š Found 3 new bookmarks to process

ğŸ”„ Phase 1: Fetching all threads from Twitter...
   Fetching thread 1/3... â³ Rate limit: waiting 0.0 minutes (0s)...
âœ“ (5 tweets)
   Fetching thread 2/3... â³ Rate limit: waiting 15.0 minutes (900s)...
âœ“ (8 tweets)
   Fetching thread 3/3... â³ Rate limit: waiting 15.0 minutes (900s)...
âœ“ (3 tweets)

ğŸ§  Phase 2: Processing 3 threads with LLM...
   Loading model into memory (one time)...
âœ“ Model loaded and ready

Generating .mdc 1/3
   Generating with pre-loaded model...
âœ“ Saved: rules/seo-growth-tactics.mdc

Generating .mdc 2/3
   Generating with pre-loaded model...
âœ“ Saved: rules/product-feedback-loop.mdc

Generating .mdc 3/3
   Generating with pre-loaded model...
âœ“ Saved: rules/startup-hiring-guide.mdc

âœ“ Sync complete! Processed 3 new threads
```

**Total time: ~30 minutes** (2 Ã— 15 min for API + 5 min for LLM)

---

## ğŸ¤” Why So Slow?

Twitter's free tier is designed for testing, not production use.

**Options:**
1. **Use free tier wisely** - Batch daily, be patient
2. **Upgrade to Basic** - $100/month, 10K tweets/month
3. **Upgrade to Pro** - $5K/month, unlimited

For personal use, free tier is fine if you:
- Process 5-10 threads per day max
- Run once daily (end of day)
- Be patient during sync

---

## ğŸ“ˆ Future Improvements

Possible optimizations (not implemented yet):
1. **Save threads to queue** - Fetch later in background
2. **Parallel user sessions** - Multiple Twitter accounts (ğŸ¤”)
3. **Smart scheduling** - Auto-sync during night
4. **Cached conversations** - Save thread data locally

For now: **Be patient, let it run, go grab coffee!** â˜•

---

Built with patience and optimization! ğŸ§µâ±ï¸

